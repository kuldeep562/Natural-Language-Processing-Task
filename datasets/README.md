# üìÅ Dataset Instructions

This folder is intended for storing datasets used across the NLP tasks. You may use your **own custom datasets** or download the recommended datasets from the official sources listed below.

## üîó Dataset Links

1. **NLTK Movie Reviews Dataset**  
   https://www.nltk.org/nltk_data/

2. **Penn Treebank Dataset**  
   https://catalog.ldc.upenn.edu/LDC99T42

3. **CoNLL-2003 NER Dataset**  
   https://www.clips.uantwerpen.be/conll2003/ner/

4. **Brown Corpus**  
   https://www.nltk.org/nltk_data/

5. **IMDB Movie Reviews Dataset**  
   https://ai.stanford.edu/~amaas/data/sentiment/

6. **20 Newsgroups Dataset**  
   http://qwone.com/~jason/20Newsgroups/

7. **WikiText-2 Dataset**  
   https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/

8. **WMT14 Translation Task (English-French)**  
   http://www.statmt.org/wmt14/translation-task.html

9. **Project Gutenberg (Literary Texts)**  
   https://www.gutenberg.org/

10. **Cornell Movie Dialogues Corpus**  
    https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html

---

You can also find these datasets on:

- **Kaggle Datasets**: https://www.kaggle.com/datasets  
- **Hugging Face Datasets**: https://huggingface.co/datasets
